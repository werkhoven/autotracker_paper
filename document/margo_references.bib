@article{Sridhar_Tracktor_2018,
  author={Sridhar, {VH} and Roche, {DG} and {bioRxiv,} Gingins~- S},
  abstract={Automated movement tracking is essential for high-throughput quantitative analyses of the behaviour and kinematics of organisms. Automated tracking also improves replicability by avoiding observer biases and allowing reproducible workflows. However, few automated tracking programs exist that are open access, open source, and capable of tracking unmarked organisms in noisy environments. Tracktor is an image-based tracking freeware designed to perform single-object tracking in noisy environments, or multi-object tracking in~…},
  journal={{bioRxiv}},
  doi={10.1101/412262},
  year={2018},
  title={Tracktor: image-based automated tracking of animal movement and behaviour}
}
@article{Itskovits_A_2017,
  author={Itskovits, Eyal and Levine, Amir and Cohen, Ehud and Zaslaver, Alon},
  abstract={Animals exhibit astonishingly complex behaviors. Studying the subtle features of these behaviors requires quantitative, high-throughput, and accurate systems that can cope with the often rich perplexing data. Here, we present a {Multi-Animal} Tracker {(MAT)} that provides a user-friendly, end-to-end solution for imaging, tracking, and analyzing complex behaviors of multiple animals simultaneously. At the core of the tracker is a machine learning algorithm that provides immense flexibility to image various animals (eg, worms, flies, zebrafish, etc.)~…},
  pages={29},
  volume={15},
  number={1},
  year={2017},
  title={A multi-animal tracker for studying complex behaviors}
}
@article{Uhlmann_FlyLimbTracker_2017,
  author={Uhlmann, V and Ramdya, P and {PLoS~…,} {Delgado-Gonzalo~-} R},
  abstract={Understanding the biological underpinnings of movement and action requires the development of tools for quantitative measurements of animal behavior. Drosophila melanogaster provides an ideal model for developing such tools: the fly has unparalleled genetic accessibility and depends on a relatively compact nervous system to generate sophisticated limbed behaviors including walking, reaching, grooming, courtship, and boxing. Here we describe a method that uses active contours to semi-automatically track~…},
  journal={{PLoS~…}},
  year={2017},
  title={{FlyLimbTracker:} An active contour based approach for leg segment tracking in unmarked, freely behaving Drosophila}
}
@article{Eyjolfsdottir_Detecting_2014,
  author={Eyjolfsdottir, E and Branson, S and Vision, {Burgos-Artizzu~-} {XP}},
  abstract={We describe a system that tracks pairs of fruit flies and automatically detects and classifies their actions. We compare experimentally the value of a frame-level feature representation with the more elaborate notion of 'bout features' that capture the structure within actions. Similarly, we compare a simple sliding window classifier architecture with a more sophisticated structured output architecture, and find that window based detectors outperform the much slower structured counterparts, and approach human performance. In~…},
  journal={…~on Computer Vision},
  year={2014},
  title={Detecting social actions of fruit flies}
}
@article{Branson_High_2009,
  pmcid={{PMC2734963}},
  author={Branson, K and Robie, {AA} and Bender, J and Nature~…, Perona~- P},
  abstract={We present a camera-based method for automatically quantifying the individual and social behaviors of fruit flies, Drosophila melanogaster, interacting in a planar arena. Our system includes machine-vision algorithms that accurately track many individuals without swapping identities and classification algorithms that detect behaviors. The data may be represented as an ethogram that plots the time course of behaviors exhibited by each fly or as a vector that concisely captures the statistical properties of all behaviors displayed in a given period~…},
  journal={Nature~…},
  year={2009},
  title={High-throughput ethomics in large groups of Drosophila}
}
@article{Liu_A_2018,
  author={Liu, G and Nath, T and Linneweber, {GA} and computational~…, Claeys~- A},
  abstract={Isolation profoundly influences social behavior in all animals. In humans, isolation has serious effects on health and disease. Drosophila melanogaster is a powerful model to study small-scale, temporally-transient social behavior. However, longer-term analysis of large groups of flies is hampered by the lack of effective and reliable tools. We built a new imaging arena and improved the existing tracking algorithm to reliably follow a large number of flies simultaneously. Next, based on the automatic classification of touch and graph-based social~…},
  journal={{PLoS} computational~…},
  year={2018},
  title={A simple computer vision pipeline reveals the effects of isolation on social interaction dynamics in Drosophila}
}
@article{Mnck_BioTracker_2018,
  author={M{\"o}nck, {HJ} and J{\"o}rg, A and von Falkenhausen, T and preprint {arXiv~…,} Tanke~- J},
  abstract={The study of animal behavior increasingly relies on (semi-) automatic methods for the extraction of relevant behavioral features from video or picture data. To date, several specialized software products exist to detect and track animals' positions in simple (laboratory) environments. Tracking animals in their natural environments, however, often requires substantial customization of the image processing algorithms to the problem-specific image characteristics. Here we introduce {BioTracker,} an open-source computer~…},
  journal={{arXiv} preprint {arXiv~…}},
  year={2018},
  title={{BioTracker:} An {Open-Source} Computer Vision Framework for Visual Animal Tracking}
}
@article{Lochmatter_Swistrack_2008,
  author={Lochmatter, T and Roduit, P and and Systems~…, Cianci~- C},
  abstract={Vision-based tracking is used in nearly all robotic laboratories for monitoring and extracting of agent positions, orientations, and trajectories. However, there is currently no accepted standard software solution available, so many research groups resort to developing and using their own custom software. In this paper, we present version 4 of {SwisTrack,} an open source project for simultaneous tracking of multiple agents. While its broad range of pre-implemented algorithmic components allows it to be used in a variety of experimental~…},
  journal={{…~Robots} and Systems~…},
  year={2008},
  title={Swistrack-a flexible open source tracking software for multi-agent systems}
}
@article{Prez-Escudero_idTracker_2014,
  author={{P{\'e}rez-Escudero,} A and {Vicente-Page,} J and Nature~…, Hinz~- {RC}},
  abstract={Animals in groups touch each other, move in paths that cross, and interact in complex ways. Current video tracking methods sometimes switch identities of unmarked individuals during these interactions. These errors propagate and result in random assignments after a few minutes unless manually corrected. We present {idTracker,} a multitracking algorithm that extracts a characteristic fingerprint from each animal in a video recording of a group. It then uses these fingerprints to identify every individual throughout the video. Tracking by~…},
  journal={Nature~…},
  year={2014},
  title={{idTracker:} tracking individuals in a group by automatic identification of unmarked animals}
}
@article{Mathis_DeepLabCut_2018,
  author={Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M and Abe, Taiga and Murthy, Venkatesh N and Mathis, Mackenzie and Bethge, Matthias},
  abstract={Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (\{\textasciitilde\}200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy. Using a deep learning approach to track user-defined body parts during various behaviors across multiple species, the authors show that their toolbox, called {DeepLabCut,} can achieve human accuracy with only a few hundred frames of training data.},
  pages={1281-1289},
  volume={21},
  number={9},
  journal={Nat Neurosci},
  pmid={30127430},
  doi={10.1038/s41593-018-0209-y},
  year={2018},
  title={{DeepLabCut:} markerless pose estimation of user-defined body parts with deep learning},
  issn={1097-6256}
}
@article{Geissmann_Ethoscopes_2017,
  author={Geissmann, Q and Rodriguez, {LG} and {PLoS~…,} Beckwith~- {EJ}},
  abstract={Here, we present the use of ethoscopes, which are machines for high-throughput analysis of behavior in Drosophila and other animals. Ethoscopes provide a software and hardware solution that is reproducible and easily scalable. They perform, in real-time, tracking and~…},
  journal={{PLoS~…}},
  year={2017},
  title={Ethoscopes: An open platform for high-throughput ethomics}
}
@article{Kain_Leg_2013,
  author={Kain, J and Stokes, C and Gaudry, Q and Song, X and Nature~…, Foley~- J},
  abstract={Much remains unknown about how the nervous system of an animal generates behaviour, and even less is known about the evolution of behaviour. How does evolution alter existing behaviours or invent novel ones? Progress in computational techniques and equipment will allow these broad, complex questions to be explored in great detail. Here we present a method for tracking each leg of a fruit fly behaving spontaneously upon a trackball, in real time. Legs were tracked with infrared-fluorescent dyes invisible to the fly, and compatible~…},
  journal={Nature~…},
  year={2013},
  title={Leg-tracking and automated behavioural classification in Drosophila}
}
@article{Donelson_High_2012,
  author={Donelson, N and Kim, {EZ} and Slawson, {JB} and one, Vecsey~- {CG}},
  abstract={Drosophila melanogaster has been used for decades in the study of circadian behavior, and more recently has become a popular model for the study of sleep. The classic method for monitoring fly activity involves counting the number of infrared beam crosses in individual small glass tubes. Incident recording methods such as this can measure gross locomotor activity, but they are unable to provide details about where the fly is located in space and do not detect small movements (ie anything less than half the enclosure size), which could lead~…},
  journal={{PloS} one},
  year={2012},
  title={High-resolution positional tracking for long-term analysis of Drosophila sleep and locomotion using the “tracker” program}
}
@article{Dankert_Automated_2009,
  pmcid={{PMC2679418}},
  author={Dankert, H and Wang, L and Hoopfer, {ED} and Nature~…, Anderson~- {DJ}},
  abstract={We introduce a method based on machine vision for automatically measuring aggression and courtship in Drosophila melanogaster. The genetic and neural circuit bases of these innate social behaviors are poorly understood. High-throughput behavioral screening in this genetically tractable model organism is a potentially powerful approach, but it is currently very laborious. Our system monitors interacting pairs of flies and computes their location, orientation and wing posture. These features are used for detecting behaviors exhibited~…},
  journal={Nature~…},
  year={2009},
  title={Automated monitoring and analysis of social behavior in Drosophila}
}
@article{Ramot_The_2008,
  author={Ramot, D and Johnson, {BE} and Jr, Berry {TL} and one, Carnell~- L},
  abstract={Background Caenorhabditis elegans locomotion is a simple behavior that has been widely used to dissect genetic components of behavior, synaptic transmission, and muscle function. Many of the paradigms that have been created to study C. elegans locomotion rely on qualitative experimenter observation. Here we report the implementation of an automated tracking system developed to quantify the locomotion of multiple individual worms in parallel. {Methodology/Principal} Findings Our tracking system generates a consistent~…},
  journal={{PloS} one},
  year={2008},
  title={The Parallel Worm Tracker: a platform for measuring average speed and drug-induced paralysis in nematodes}
}
@article{Fry_TrackFly_2008,
  author={Fry, {SN} and Rohrseitz, N and Straw, {AD} and of neuroscience, Dickinson~- {MH}},
  abstract={Modern neuroscience and the interest in biomimetic control design demand increasingly sophisticated experimental techniques that can be applied in freely moving animals under realistic behavioral conditions. To explore sensorimotor flight control mechanisms in free-flying fruit flies {(Drosophila} melanogaster), we equipped a wind tunnel with a Virtual Reality {(VR)} display system based on standard digital hardware and a {3D} path tracking system. We demonstrate the experimental power of this approach by example of a 'one-parameter open~…},
  journal={Journal of neuroscience~…},
  year={2008},
  title={{TrackFly:} virtual reality for a behavioral system analysis in free-flying fruit flies}
}
