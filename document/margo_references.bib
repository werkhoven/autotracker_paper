@article{Buchanan_Neuronal_2015,
  author={Buchanan, Sean M and Kain, Jamey S and de Bivort, Benjamin L},
  abstract={Genetically identical individuals display variability in their physiology, morphology, and behaviors, even when reared in essentially identical environments, but there is little mechanistic understanding of the basis of such variation. Here, we investigated whether Drosophila melanogaster displays individual-to-individual variation in locomotor behaviors. We developed a new high-throughout platform capable of measuring the exploratory behavior of hundreds of individual flies simultaneously. With this approach, we find that, during exploratory walking, individual flies exhibit significant bias in their left vs. right locomotor choices, with some flies being strongly left biased or right biased. This idiosyncrasy was present in all genotypes examined, including wild-derived populations and inbred isogenic laboratory strains. The biases of individual flies persist for their lifetime and are nonheritable: i.e., mating two left-biased individuals does not yield left-biased progeny. This locomotor handedness is uncorrelated with other asymmetries, such as the handedness of gut twisting, leg-length asymmetry, and wing-folding preference. Using transgenics and mutants, we find that the magnitude of locomotor handedness is under the control of columnar neurons within the central complex, a brain region implicated in motor planning and execution. When these neurons are silenced, exploratory laterality increases, with more extreme leftiness and rightiness. This observation intriguingly implies that the brain may be able to dynamically regulate behavioral individuality.},
  journal={Proceedings of the~…},
  pmid={25953337},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Buchanan et al-2015-Proceedings of the National Academy of Sciences of the United States of America.pdf},
  doi={10.1073/pnas.1500804112},
  year={2015},
  title={Neuronal control of locomotor handedness in Drosophila.},
  issn={0027-8424}
}
@article{Sridhar_Tracktor_2018,
  author={Sridhar, {VH} and Roche, {DG} and {bioRxiv,} Gingins~- S},
  abstract={Automated movement tracking is essential for high-throughput quantitative analyses of the behaviour and kinematics of organisms. Automated tracking also improves replicability by avoiding observer biases and allowing reproducible workflows. However, few automated tracking programs exist that are open access, open source, and capable of tracking unmarked organisms in noisy environments. Tracktor is an image-based tracking freeware designed to perform single-object tracking in noisy environments, or multi-object tracking in~…},
  journal={{bioRxiv}},
  doi={10.1101/412262},
  year={2018},
  title={Tracktor: image-based automated tracking of animal movement and behaviour}
}
@article{Itskovits_A_2017,
  author={Itskovits, Eyal and Levine, Amir and Cohen, Ehud and Zaslaver, Alon},
  abstract={Animals exhibit astonishingly complex behaviors. Studying the subtle features of these behaviors requires quantitative, high-throughput, and accurate systems that can cope with the often rich perplexing data. Here, we present a {Multi-Animal} Tracker {(MAT)} that provides a user-friendly, end-to-end solution for imaging, tracking, and analyzing complex behaviors of multiple animals simultaneously. At the core of the tracker is a machine learning algorithm that provides immense flexibility to image various animals (eg, worms, flies, zebrafish, etc.)~…},
  pages={29},
  volume={15},
  number={1},
  year={2017},
  title={A multi-animal tracker for studying complex behaviors}
}
@article{Uhlmann_FlyLimbTracker_2017,
  author={Uhlmann, V and Ramdya, P and {PLoS~…,} {Delgado-Gonzalo~-} R},
  abstract={Understanding the biological underpinnings of movement and action requires the development of tools for quantitative measurements of animal behavior. Drosophila melanogaster provides an ideal model for developing such tools: the fly has unparalleled genetic accessibility and depends on a relatively compact nervous system to generate sophisticated limbed behaviors including walking, reaching, grooming, courtship, and boxing. Here we describe a method that uses active contours to semi-automatically track~…},
  journal={{PLoS~…}},
  year={2017},
  title={{FlyLimbTracker:} An active contour based approach for leg segment tracking in unmarked, freely behaving Drosophila}
}
@article{Eyjolfsdottir_Detecting_2014,
  author={Eyjolfsdottir, E and Branson, S and Vision, {Burgos-Artizzu~-} {XP}},
  abstract={We describe a system that tracks pairs of fruit flies and automatically detects and classifies their actions. We compare experimentally the value of a frame-level feature representation with the more elaborate notion of 'bout features' that capture the structure within actions. Similarly, we compare a simple sliding window classifier architecture with a more sophisticated structured output architecture, and find that window based detectors outperform the much slower structured counterparts, and approach human performance. In~…},
  journal={…~on Computer Vision},
  year={2014},
  title={Detecting social actions of fruit flies}
}
@article{Branson_High_2009,
  pmcid={{PMC2734963}},
  author={Branson, K and Robie, {AA} and Bender, J and Nature~…, Perona~- P},
  abstract={We present a camera-based method for automatically quantifying the individual and social behaviors of fruit flies, Drosophila melanogaster, interacting in a planar arena. Our system includes machine-vision algorithms that accurately track many individuals without swapping identities and classification algorithms that detect behaviors. The data may be represented as an ethogram that plots the time course of behaviors exhibited by each fly or as a vector that concisely captures the statistical properties of all behaviors displayed in a given period~…},
  journal={Nature~…},
  year={2009},
  title={High-throughput ethomics in large groups of Drosophila}
}
@article{Liu_A_2018,
  author={Liu, G and Nath, T and Linneweber, {GA} and computational~…, Claeys~- A},
  abstract={Isolation profoundly influences social behavior in all animals. In humans, isolation has serious effects on health and disease. Drosophila melanogaster is a powerful model to study small-scale, temporally-transient social behavior. However, longer-term analysis of large groups of flies is hampered by the lack of effective and reliable tools. We built a new imaging arena and improved the existing tracking algorithm to reliably follow a large number of flies simultaneously. Next, based on the automatic classification of touch and graph-based social~…},
  journal={{PLoS} computational~…},
  year={2018},
  title={A simple computer vision pipeline reveals the effects of isolation on social interaction dynamics in Drosophila}
}
@article{Mnck_BioTracker_2018,
  author={M{\"o}nck, {HJ} and J{\"o}rg, A and von Falkenhausen, T and preprint {arXiv~…,} Tanke~- J},
  abstract={The study of animal behavior increasingly relies on (semi-) automatic methods for the extraction of relevant behavioral features from video or picture data. To date, several specialized software products exist to detect and track animals' positions in simple (laboratory) environments. Tracking animals in their natural environments, however, often requires substantial customization of the image processing algorithms to the problem-specific image characteristics. Here we introduce {BioTracker,} an open-source computer~…},
  journal={{arXiv} preprint {arXiv~…}},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Mnck et al-2018-arXiv preprint arXiv.pdf},
  year={2018},
  title={{BioTracker:} An {Open-Source} Computer Vision Framework for Visual Animal Tracking}
}
@article{Lochmatter_Swistrack_2008,
  author={Lochmatter, T and Roduit, P and and Systems~…, Cianci~- C},
  abstract={Vision-based tracking is used in nearly all robotic laboratories for monitoring and extracting of agent positions, orientations, and trajectories. However, there is currently no accepted standard software solution available, so many research groups resort to developing and using their own custom software. In this paper, we present version 4 of {SwisTrack,} an open source project for simultaneous tracking of multiple agents. While its broad range of pre-implemented algorithmic components allows it to be used in a variety of experimental~…},
  journal={{…~Robots} and Systems~…},
  year={2008},
  title={Swistrack-a flexible open source tracking software for multi-agent systems}
}
@article{Prez-Escudero_idTracker_2014,
  author={{P{\'e}rez-Escudero,} A and {Vicente-Page,} J and Nature~…, Hinz~- {RC}},
  abstract={Animals in groups touch each other, move in paths that cross, and interact in complex ways. Current video tracking methods sometimes switch identities of unmarked individuals during these interactions. These errors propagate and result in random assignments after a few minutes unless manually corrected. We present {idTracker,} a multitracking algorithm that extracts a characteristic fingerprint from each animal in a video recording of a group. It then uses these fingerprints to identify every individual throughout the video. Tracking by~…},
  journal={Nature~…},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Prez-Escudero et al-2014-Nature.pdf},
  year={2014},
  title={{idTracker:} tracking individuals in a group by automatic identification of unmarked animals}
}
@article{Mathis_DeepLabCut_2018,
  author={Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M and Abe, Taiga and Murthy, Venkatesh N and Mathis, Mackenzie and Bethge, Matthias},
  abstract={Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (\{\textasciitilde\}200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy. Using a deep learning approach to track user-defined body parts during various behaviors across multiple species, the authors show that their toolbox, called {DeepLabCut,} can achieve human accuracy with only a few hundred frames of training data.},
  pages={1281-1289},
  volume={21},
  number={9},
  journal={Nat Neurosci},
  pmid={30127430},
  doi={10.1038/s41593-018-0209-y},
  year={2018},
  title={{DeepLabCut:} markerless pose estimation of user-defined body parts with deep learning},
  issn={1097-6256}
}
@article{Geissmann_Ethoscopes_2017,
  author={Geissmann, Q and Rodriguez, {LG} and {PLoS~…,} Beckwith~- {EJ}},
  abstract={Here, we present the use of ethoscopes, which are machines for high-throughput analysis of behavior in Drosophila and other animals. Ethoscopes provide a software and hardware solution that is reproducible and easily scalable. They perform, in real-time, tracking and~…},
  journal={{PLoS~…}},
  year={2017},
  title={Ethoscopes: An open platform for high-throughput ethomics}
}
@article{Kain_Leg_2013,
  author={Kain, J and Stokes, C and Gaudry, Q and Song, X and Nature~…, Foley~- J},
  abstract={Much remains unknown about how the nervous system of an animal generates behaviour, and even less is known about the evolution of behaviour. How does evolution alter existing behaviours or invent novel ones? Progress in computational techniques and equipment will allow these broad, complex questions to be explored in great detail. Here we present a method for tracking each leg of a fruit fly behaving spontaneously upon a trackball, in real time. Legs were tracked with infrared-fluorescent dyes invisible to the fly, and compatible~…},
  journal={Nature~…},
  year={2013},
  title={Leg-tracking and automated behavioural classification in Drosophila}
}
@article{Donelson_High_2012,
  author={Donelson, N and Kim, {EZ} and Slawson, {JB} and one, Vecsey~- {CG}},
  abstract={Drosophila melanogaster has been used for decades in the study of circadian behavior, and more recently has become a popular model for the study of sleep. The classic method for monitoring fly activity involves counting the number of infrared beam crosses in individual small glass tubes. Incident recording methods such as this can measure gross locomotor activity, but they are unable to provide details about where the fly is located in space and do not detect small movements (ie anything less than half the enclosure size), which could lead~…},
  journal={{PloS} one},
  year={2012},
  title={High-resolution positional tracking for long-term analysis of Drosophila sleep and locomotion using the “tracker” program}
}
@article{Dankert_Automated_2009,
  pmcid={{PMC2679418}},
  author={Dankert, H and Wang, L and Hoopfer, {ED} and Nature~…, Anderson~- {DJ}},
  abstract={We introduce a method based on machine vision for automatically measuring aggression and courtship in Drosophila melanogaster. The genetic and neural circuit bases of these innate social behaviors are poorly understood. High-throughput behavioral screening in this genetically tractable model organism is a potentially powerful approach, but it is currently very laborious. Our system monitors interacting pairs of flies and computes their location, orientation and wing posture. These features are used for detecting behaviors exhibited~…},
  journal={Nature~…},
  year={2009},
  title={Automated monitoring and analysis of social behavior in Drosophila}
}
@article{Ramot_The_2008,
  author={Ramot, D and Johnson, {BE} and Jr, Berry {TL} and one, Carnell~- L},
  abstract={Background Caenorhabditis elegans locomotion is a simple behavior that has been widely used to dissect genetic components of behavior, synaptic transmission, and muscle function. Many of the paradigms that have been created to study C. elegans locomotion rely on qualitative experimenter observation. Here we report the implementation of an automated tracking system developed to quantify the locomotion of multiple individual worms in parallel. {Methodology/Principal} Findings Our tracking system generates a consistent~…},
  journal={{PloS} one},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Ramot et al-2008-PloS one.pdf},
  year={2008},
  title={The Parallel Worm Tracker: a platform for measuring average speed and drug-induced paralysis in nematodes}
}
@article{Fry_TrackFly_2008,
  author={Fry, {SN} and Rohrseitz, N and Straw, {AD} and of neuroscience, Dickinson~- {MH}},
  abstract={… This time lag is composed of the time required: (1) by Trackit {3D} to send a position message
after the image of the fly was sampled by the cameras, and (2) the image rendering system
to render an image according to the measured fly's {3D} position~… 
},
  journal={Journal of neuroscience~…},
  year={2008},
  title={{TrackFly:} virtual reality for a behavioral system analysis in free-flying fruit flies}
}
@article{Swierczek_High_2011,
  pmcid={{PMC3128206}},
  author={Swierczek, {NA} and Giles, {AC} and Rankin, {CH} and methods, Kerr~- {RA}},
  abstract={We designed a real-time computer vision system, the {Multi-Worm} Tracker {(MWT),} which can simultaneously quantify the behavior of dozens of Caenorhabditis elegans on a Petri plate at video rates. We examined three traditional behavioral paradigms using this system: spontaneous movement on food, where the behavior changes over tens of minutes; chemotaxis, where turning events must be detected accurately to determine strategy; and habituation of response to tap, where the response is stochastic and changes over time. In~…},
  journal={Nature methods},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Swierczek et al-2011-Nature methods.pdf},
  year={2011},
  title={High-throughput behavioral analysis in C. elegans}
}
@article{Pereira_Fast_2018,
  author={Pereira, {TD} and Aldarondo, {DE} and Willmore, L and {bioRxiv,} Kislin~- M},
  abstract={Recent work quantifying postural dynamics has attempted to define the repertoire of behaviors performed by an animal. However, a major drawback to these techniques has been their reliance on dimensionality reduction of images which destroys information about which parts of the body are used in each behavior. To address this issue, we introduce a deep learning-based method for pose estimation, {LEAP} {(LEAP} Estimates Animal Pose). {LEAP} automatically predicts the positions of animal body parts using a deep convolutional~…},
  journal={{bioRxiv}},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Pereira et al-2018-bioRxiv.pdf},
  doi={10.1101/331181},
  year={2018},
  title={Fast animal pose estimation using deep neural networks}
}
@article{Ayroles_Behavioral_2015,
  author={Ayroles, {JF} and Buchanan, {SM} and of the~…, {O'Leary~-} C},
  abstract={Quantitative genetics has primarily focused on describing genetic effects on trait means and largely ignored the effect of alternative alleles on trait variability, potentially missing an important axis of genetic variation contributing to phenotypic differences among individuals. To study the genetic effects on individual-to-individual phenotypic variability (or intragenotypic variability), we used Drosophila inbred lines and measured the spontaneous locomotor behavior of flies walking individually in Y-shaped mazes, focusing on variability in~…},
  journal={Proceedings of the~…},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Ayroles et al-2015-Proceedings of the.pdf},
  doi={10.1073/pnas.1503830112},
  year={2015},
  title={Behavioral idiosyncrasy reveals genetic control of phenotypic variability}
}
@article{Chagas_The_2017,
  author={Chagas, {AM} and {Prieto-Godino,} {LL} and {PLoS~…,} Arrenberg~- {AB}},
  abstract={Small, genetically tractable species such as larval zebrafish, Drosophila, or Caenorhabditis elegans have become key model organisms in modern neuroscience. In addition to their low maintenance costs and easy sharing of strains across labs, one key appeal is the possibility to monitor single or groups of animals in a behavioural arena while controlling the activity of select neurons using optogenetic or thermogenetic tools. However, the purchase of a commercial solution for these types of experiments, including an appropriate camera system~…},
  journal={{PLoS~…}},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Chagas et al-2017-PLoS.pdf},
  year={2017},
  title={The€ 100 lab: A {3D-printable} open-source platform for fluorescence microscopy, optogenetics, and accurate temperature control during behaviour of zebrafish~…}
}
@article{Fujiwara_A_2017,
  author={Fujiwara, T and Cruz, {TL} and Bohnslav, {JP} and neuroscience, Chiappe~- {ME}},
  abstract={The integration of sensorimotor signals to internally estimate self-movement is critical for spatial perception and motor control. However, which neural circuits accurately track body motion and how these circuits control movement remain unknown. We found that a ~…},
  journal={Nature neuroscience},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Fujiwara et al-2017-Nature neuroscience.pdf},
  year={2017},
  title={A faithful internal representation of walking movements in the Drosophila visual system}
}
@article{Straw_Multi_2011,
  author={Straw, {AD} and of The~…, Branson~- K},
  abstract={Automated tracking of animal movement allows analyses that would not otherwise be possible by providing great quantities of data. The additional capability of tracking in real time—with minimal latency—opens up the experimental possibility of manipulating sensory feedback, thus allowing detailed explorations of the neural basis for control of behaviour. Here, we describe a system capable of tracking the three-dimensional position and body orientation of animals such as flies and birds. The system operates with less than 40 ms~…},
  journal={Journal of The~…},
  pmid={20630879},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Straw et al-2011-Journal of The.pdf},
  doi={10.1098/rsif.2010.0230},
  year={2011},
  title={Multi-camera real-time three-dimensional tracking of multiple flying animals},
  issn={1742-5689}
}
@article{Stowers_Virtual_2017,
  author={Stowers, {JR} and Hofbauer, M and Bastien, R and Nature~…, Griessner~- J},
  abstract={Standard animal behavior paradigms incompletely mimic nature and thus limit our understanding of behavior and brain function. Virtual reality {(VR)} can help, but it poses challenges. Typical {VR} systems require movement restrictions but disrupt sensorimotor experience, causing neuronal and behavioral alterations. We report the development of {FreemoVR,} a {VR} system for freely moving animals. We validate immersive {VR} for mice, flies, and zebrafish. {FreemoVR} allows instant, disruption-free environmental reconfigurations and~…},
  journal={Nature~…},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Stowers et al-2017-Nature.pdf},
  year={2017},
  title={Virtual reality for freely moving animals}
}
@article{Rodriguez_ToxId_2017,
  author={Rodriguez, A and Zhang, H and Klaminder, J and reports, Brodin~- T},
  abstract={Video analysis of animal behaviour is widely used in fields such as ecology, ecotoxicology, and evolutionary research. However, when tracking multiple animals, occlusion and crossing are problematic, especially when the identity of each individual needs to be preserved. We present a new algorithm, {ToxId,} which preserves the identity of multiple animals by linking trajectory segments using their intensity histogram and Hu-moments. We verify the performance and accuracy of our algorithm using video sequences with different~…},
  journal={Scientific reports},
  year={2017},
  title={{ToxId:} an efficient algorithm to solve occlusions when tracking multiple animals}
}
@article{Kim_Fly_2016,
  author={Kim, S and Tellez, K and Buchan, G and in molecular, Lebestky~- T},
  abstract={Optomotor behavior represents a stereotyped locomotor response to visual motion that is found in both vertebrate and invertebrate models. The Fly Stampede assay was developed to study an optomotor response in freely walking populations of Drosophila. Here we share~…},
  journal={Frontiers in molecular~…},
  file={C:\Users\winsl0w\Documents\ReadCube Media\Kim et al-2016-Frontiers in molecular.pdf},
  year={2016},
  title={Fly Stampede 2.0: A Next Generation Optomotor Assay for Walking Behavior in Drosophila Melanogaster}
}
@article{Zhu_Peripheral_2009,
  author={Zhu, Y and Nern, A and Zipursky, {SL} and Biology, Frye~- {MA}},
  abstract={… robust optomotor responses reminiscent of a “stampede.” {(Left)} Heat map shows the average
spatial distribution of flies during three test phases. Image motion progresses first centrifugally
outward and then centripetally inward and then is switched off. Counts of fly position are~… 
},
  journal={Current Biology},
  year={2009},
  title={Peripheral visual circuits functionally segregate motion and phototaxis behaviors in the fly}
}
@article{Seelig_Two_2010,
  pmcid={{PMC2945246}},
  author={Seelig, {JD} and Chiappe, {ME} and Lott, {GK} and Dutta, A and Nature~…, Osborne~- {JE}},
  abstract={Drosophila melanogaster is a model organism rich in genetic tools to manipulate and identify neural circuits involved in specific behaviors. Here we present a technique for two-photon calcium imaging in the central brain of head-fixed Drosophila walking on an air-supported ball. The ball's motion is tracked at high resolution and can be treated as a proxy for the fly's own movements. We used the genetically encoded calcium sensor, {GCaMP3.} 0, to record from important elements of the motion-processing pathway, the horizontal-system~…},
  journal={Nature~…},
  year={2010},
  title={Two-photon calcium imaging from head-fixed Drosophila during optomotor walking behavior}
}
@article{Gtz_Visual_1973,
  author={G{\"o}tz, {KG} and of comparative physiology, Wenking~- H},
  abstract={To investigate the optomotor leg responses of Drosophila melanogaster the free walking fly is kept in stationary orientation and position on top of a ball. The stimulus consists of continuous pattern movement in the equatorial zone of the visual field. The rotatory and translatory responses are derived from the signals of a servo-system which maintains the stationary state of the walking fly by appropriate rotations of the ball. Course control, or the tendency to follow rotatory displacements of the visual surroundings, is established in the~…},
  journal={Journal of comparative physiology},
  year={1973},
  title={Visual control of locomotion in the walking {fruitflyDrosophila}}
}
